{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shavit/APhotoADay/data/stylegan-encoder/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shavit/APhotoADay/data/stylegan-encoder/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shavit/APhotoADay/data/stylegan-encoder/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shavit/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# path to stylegan encoder on server\n",
    "sys.path.insert(1, '/home/shavit/APhotoADay/data/stylegan-encoder')\n",
    "\n",
    "from encoder.generator_model import Generator\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shavit/APhotoADay/data/stylegan-encoder/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shavit/APhotoADay/data/stylegan-encoder/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From <string>:364: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "2 root error(s) found.\n  (0) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_D/32x32/Conv1_down/weight/new_value_0_19}}]]\n\t [[D/FromRGB_lod6/bias/setter/_795]]\n  (1) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_D/32x32/Conv1_down/weight/new_value_0_19}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_D/32x32/Conv1_down/weight/new_value_0_19}}]]\n\t [[D/FromRGB_lod6/bias/setter/_795]]\n  (1) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_D/32x32/Conv1_down/weight/new_value_0_19}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a7d3c01419dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL_FFHQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgenerator_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/APhotoADay/data/stylegan-encoder/dnnlib/tflib/network.py\u001b[0m in \u001b[0;36m__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_own_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mtfutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"variables\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_static_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Network\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/APhotoADay/data/stylegan-encoder/dnnlib/tflib/tfutil.py\u001b[0m in \u001b[0;36mset_vars\u001b[0;34m(var_to_value_dict)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/APhotoADay/data/stylegan-encoder/dnnlib/tflib/tfutil.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"\"\"Run the specified ops in the default session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0massert_tf_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_D/32x32/Conv1_down/weight/new_value_0_19}}]]\n\t [[D/FromRGB_lod6/bias/setter/_795]]\n  (1) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_D/32x32/Conv1_down/weight/new_value_0_19}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "URL_FFHQ = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'\n",
    "\n",
    "tflib.init_tf()\n",
    "with dnnlib.util.open_url(URL_FFHQ, cache_dir=config.cache_dir) as f:\n",
    "    generator_network, discriminator_network, Gs_network = pickle.load(f)\n",
    "    \n",
    "# sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "\n",
    "generator = Generator(Gs_network, batch_size=1, randomize_noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string, color=None):\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))\n",
    "\n",
    "printmd(\"Please enter number of dimensions:\", color=\"blue\")\n",
    "dimensions = int(input())\n",
    "\n",
    "printmd(\"Please choose data [1-external, 2-internal]:\", color=\"red\")\n",
    "data_loc = int(input())\n",
    "\n",
    "data_method = \"external\"\n",
    "if data_loc == 2:\n",
    "    data_method = \"internal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "# os.chdir(\"/home/shavit/APhotoADay/True_vs_Learned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "# data is a list of lists where the first element is the age and the second is the latent representation\n",
    "\n",
    "# i.e. data[0] contains the entire first video\n",
    "# data[0][0] is a list of two values (the first age of the video, and the latent representation of the photo at that age)\n",
    "\n",
    "data = []\n",
    "\n",
    "video = []\n",
    "\n",
    "paths = [\"regression_data/video1\",\n",
    "         \"regression_data/video2\",\n",
    "         \"regression_data/video3\"]\n",
    "\n",
    "for path in paths:\n",
    "    \n",
    "    for photo in os.listdir(path):\n",
    "\n",
    "        latent_representation = np.load(path + \"/\" + photo).flatten()\n",
    "        age = int(Path(photo).stem)\n",
    "\n",
    "        video.append([age, latent_representation])\n",
    "        video.sort()\n",
    "        \n",
    "    data.append(video)\n",
    "    video = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most linear components in data\n",
    "\n",
    "# find differences\n",
    "differences = []\n",
    "\n",
    "for person in data:\n",
    "    for j, photo in enumerate(person):\n",
    "        if j == 0:\n",
    "            continue\n",
    "        differences.append(photo[1] - person[j - 1][1])\n",
    "\n",
    "differences = np.array(differences)\n",
    "\n",
    "differences_aux = differences.transpose()\n",
    "\n",
    "normalized_differences_aux = preprocessing.normalize(np.array(differences_aux))\n",
    "\n",
    "variances = []\n",
    "normalized_variances = []\n",
    "\n",
    "for values in differences_aux:\n",
    "    variances.append(np.var(values))\n",
    "\n",
    "for values in normalized_differences_aux:\n",
    "    normalized_variances.append(np.var(values))\n",
    "    \n",
    "# list of components sorted by variance\n",
    "smallest_variance_components = np.argsort(variances)\n",
    "normalized_smallest_variance_components = np.argsort(normalized_variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_first_10 = copy.deepcopy(data)\n",
    "data_most_linear = copy.deepcopy(data)\n",
    "data_normalized_most_linear = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, person in enumerate(data_first_10):\n",
    "    for j, photo in enumerate(person):\n",
    "        #print (\"first 10 = \")\n",
    "        #print (data_first_10[i][j][1][0:10])\n",
    "        data_first_10[i][j][1] =  np.concatenate((data_first_10[i][j][1][0:dimensions], np.zeros(512*18 - dimensions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_variance_components = np.concatenate((smallest_variance_components[0:dimensions], np.ones(512*18 - dimensions) * (-1)))\n",
    "\n",
    "for i, person in enumerate(data_most_linear):\n",
    "    for j, photo in enumerate(person):\n",
    "        for k, component in enumerate(photo[1]):\n",
    "            if (k in smallest_variance_components) == False:\n",
    "                data_most_linear[i][j][1][k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_smallest_variance_components = np.concatenate((normalized_smallest_variance_components[0:dimensions], np.ones(512*18 - dimensions) * (-1)))\n",
    "\n",
    "for i, person in enumerate(data_normalized_most_linear):\n",
    "    for j, photo in enumerate(person):\n",
    "        for k, component in enumerate(photo[1]):\n",
    "            if (k in normalized_smallest_variance_components) == False:\n",
    "                data_normalized_most_linear[i][j][1][k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRegressor(start_ages, start_photos, target_ages, target_photos):\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(start_photos)):\n",
    "        X.append(np.concatenate([start_photos[i], start_ages[i], target_ages[i]], axis=None))\n",
    "        Y.append(target_photos[i] - start_photos[i])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "    regressor = LinearRegression(copy_X = True)  \n",
    "    regressor.fit(X_train, Y_train)\n",
    "\n",
    "    #print(\"accuracy = \" + str(testModel(X_train, Y_train, regressor)))\n",
    "\n",
    "    return regressor, np.array(X_test).astype(np.float64), np.array(Y_test).astype(np.float64), np.array(X_train).astype(np.float64), np.array(Y_train).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for first 10 dimensions\n",
    "start_ages_f10 = []\n",
    "start_photos_f10 = []\n",
    "target_ages_f10 = []\n",
    "target_photos_f10 = []\n",
    "\n",
    "for person in data_first_10:\n",
    "    first_age = person[0][0]\n",
    "    first_photo = person[0][1]\n",
    "    for photo in person:\n",
    "        start_photos_f10.append(first_photo)\n",
    "        start_ages_f10.append(first_age)\n",
    "        target_ages_f10.append(photo[0])\n",
    "        target_photos_f10.append(photo[1])\n",
    "\n",
    "regressor_first_10, X_test_f10, Y_test_f10, X_train_f10, Y_train_f10 = findRegressor (start_ages_f10, start_photos_f10, target_ages_f10, target_photos_f10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_differences_f10 = regressor_first_10.predict(X_test_f10)\n",
    "predicted_results_f10 = []\n",
    "for i, difference in enumerate(predicted_differences_f10):\n",
    "    predicted_results_f10.append(start_photos_f10[i] + difference)\n",
    "MSE_f10 = metrics.mean_squared_error (Y_test_f10, predicted_results_f10)\n",
    "predicted_differences_f10_train = regressor_first_10.predict(X_train_f10)\n",
    "predicted_results_f10_train = []\n",
    "for i, difference in enumerate(predicted_differences_f10_train):\n",
    "    predicted_results_f10_train.append(start_photos_f10[i] + difference)\n",
    "MSE_f10_train = metrics.mean_squared_error (predicted_differences_f10_train, Y_train_f10)\n",
    "\n",
    "print (MSE_f10_train)\n",
    "print (MSE_f10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New code\n",
    "age_specific_MSE_f10 = []\n",
    "\n",
    "for i, age in enumerate(Y_test_f10):\n",
    "    this_MSE = metrics.mean_squared_error (Y_test_f10[i], predicted_results_f10[i])\n",
    "    age_specific_MSE_f10.append([X_test_f10[i][512*18 + 1], this_MSE])\n",
    "\n",
    "age_specific_MSE_f10.sort()\n",
    "\n",
    "path_e = \"regression_data/results/dimensions/first_\" + str(dimensions) + data_method\n",
    "if not os.path.exists(path_e):\n",
    "    os.mkdir(path_e)\n",
    "\n",
    "graph_name = path_e + \"/error_graph\"\n",
    "csv_file = graph_name + \".csv\"\n",
    "\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Age\", \"MSE\"])\n",
    "    \n",
    "    for age, mse in age_specific_MSE_f10:\n",
    "        writer.writerow([(age / 365.0), mse])\n",
    "\n",
    "# Display and save plot\n",
    "\n",
    "data_to_plot = pd.read_csv(csv_file).set_index('Age')\n",
    "data_plot = data_to_plot.plot(title = \"Age vs Regression Error\", legend = None)\n",
    "\n",
    "data_plot.get_figure().savefig(graph_name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for smallest variance\n",
    "start_ages_sv = []\n",
    "start_photos_sv = []\n",
    "target_ages_sv = []\n",
    "target_photos_sv = []\n",
    "\n",
    "for person in data_most_linear:\n",
    "    first_age = person[0][0]\n",
    "    first_photo = person[0][1]\n",
    "    for photo in person:\n",
    "        start_photos_sv.append(first_photo)\n",
    "        start_ages_sv.append(first_age)\n",
    "        target_ages_sv.append(photo[0])\n",
    "        target_photos_sv.append(photo[1])\n",
    "\n",
    "regressor_smallest_variance, X_test_sv, Y_test_sv, X_train_sv, Y_train_sv = findRegressor (start_ages_sv, start_photos_sv, target_ages_sv, target_photos_sv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_differences_sv = regressor_smallest_variance.predict(X_test_sv)\n",
    "predicted_results_sv = []\n",
    "for i, difference in enumerate(predicted_differences_sv):\n",
    "    predicted_results_sv.append(start_photos_sv[i] + difference)\n",
    "MSE_sv = metrics.mean_squared_error (Y_test_sv, predicted_results_sv)\n",
    "predicted_differences_sv_train = regressor_smallest_variance.predict(X_train_sv)\n",
    "predicted_results_sv_train = []\n",
    "for i, difference in enumerate(predicted_differences_sv_train):\n",
    "    predicted_results_sv_train.append(start_photos_sv[i] + difference)\n",
    "MSE_sv_train = metrics.mean_squared_error (predicted_differences_sv_train, Y_train_sv)\n",
    "\n",
    "print (MSE_sv_train)\n",
    "print (MSE_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New code\n",
    "age_specific_MSE_sv = []\n",
    "\n",
    "for i, age in enumerate(Y_test_sv):\n",
    "    this_MSE = metrics.mean_squared_error (Y_test_sv[i], predicted_results_sv[i])\n",
    "    age_specific_MSE_sv.append([X_test_sv[i][512*18 + 1], this_MSE])\n",
    "\n",
    "age_specific_MSE_sv.sort()\n",
    "\n",
    "path_e = \"regression_data/results/dimensions/linear_first_\" + str(dimensions) + data_method\n",
    "if not os.path.exists(path_e):\n",
    "    os.mkdir(path_e)\n",
    "\n",
    "graph_name = path_e + \"/error_graph\"\n",
    "csv_file = graph_name + \".csv\"\n",
    "\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Age\", \"MSE\"])\n",
    "    \n",
    "    for age, mse in age_specific_MSE_sv:\n",
    "        writer.writerow([(age / 365.0), mse])\n",
    "\n",
    "# Display and save plot\n",
    "\n",
    "data_to_plot = pd.read_csv(csv_file).set_index('Age')\n",
    "data_plot = data_to_plot.plot(title = \"Age vs Regression Error\", legend = None)\n",
    "\n",
    "data_plot.get_figure().savefig(graph_name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for smallest variance\n",
    "start_ages_nsv = []\n",
    "start_photos_nsv = []\n",
    "target_ages_nsv = []\n",
    "target_photos_nsv = []\n",
    "\n",
    "for person in data_normalized_most_linear:\n",
    "    first_age = person[0][0]\n",
    "    first_photo = person[0][1]\n",
    "    for photo in person:\n",
    "        start_photos_nsv.append(first_photo)\n",
    "        start_ages_nsv.append(first_age)\n",
    "        target_ages_nsv.append(photo[0])\n",
    "        target_photos_nsv.append(photo[1])\n",
    "\n",
    "regressor_normalized_smallest_variance, X_test_nsv, Y_test_nsv, X_train_nsv, Y_train_nsv = findRegressor (start_ages_nsv, start_photos_nsv, target_ages_nsv, target_photos_nsv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_differences_nsv = regressor_normalized_smallest_variance.predict(X_test_nsv)\n",
    "predicted_results_nsv = []\n",
    "for i, difference in enumerate(predicted_differences_nsv):\n",
    "    predicted_results_nsv.append(start_photos_nsv[i] + difference)\n",
    "MSE_nsv = metrics.mean_squared_error (Y_test_nsv, predicted_results_nsv)\n",
    "predicted_differences_nsv_train = regressor_normalized_smallest_variance.predict(X_train_nsv)\n",
    "predicted_results_nsv_train = []\n",
    "for i, difference in enumerate(predicted_differences_nsv_train):\n",
    "    predicted_results_nsv_train.append(start_photos_nsv[i] + difference)\n",
    "MSE_nsv_train = metrics.mean_squared_error (predicted_differences_nsv_train, Y_train_nsv)\n",
    "\n",
    "print (MSE_nsv_train)\n",
    "print (MSE_nsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New code\n",
    "age_specific_MSE_nsv = []\n",
    "\n",
    "for i, age in enumerate(Y_test_nsv):\n",
    "    this_MSE = metrics.mean_squared_error (Y_test_nsv[i], predicted_results_nsv[i])\n",
    "    age_specific_MSE_nsv.append([X_test_nsv[i][512*18 + 1], this_MSE])\n",
    "\n",
    "age_specific_MSE_nsv.sort()\n",
    "\n",
    "path_e = \"regression_data/results/dimensions/norm_linear_first_\" + str(dimensions) + data_method\n",
    "if not os.path.exists(path_e):\n",
    "    os.mkdir(path_e)\n",
    "\n",
    "graph_name = path_e + \"/error_graph\"\n",
    "csv_file = graph_name + \".csv\"\n",
    "\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Age\", \"MSE\"])\n",
    "    \n",
    "    for age, mse in age_specific_MSE_nsv:\n",
    "        writer.writerow([(age / 365.0), mse])\n",
    "\n",
    "# Display and save plot\n",
    "\n",
    "data_to_plot = pd.read_csv(csv_file).set_index('Age')\n",
    "data_plot = data_to_plot.plot(title = \"Age vs Regression Error\", legend = None)\n",
    "\n",
    "data_plot.get_figure().savefig(graph_name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(latent_vector, size):\n",
    "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
    "    generator.set_dlatents(latent_vector)\n",
    "    img_array = generator.generate_images()[0]\n",
    "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
    "    return img.resize((size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video from given picture, using our data (which specific data exactly?)\n",
    "\n",
    "os.chdir(\"/home/shavit/APhotoADay/True_vs_Learned\")\n",
    "\n",
    "t_start_photos = []\n",
    "t_start_ages = []\n",
    "t_target_ages = []\n",
    "    \n",
    "t_first = np.load(\"regression_data/test/emma.npy\").flatten()\n",
    "# t_first_age = int(input(\"Enter your age (years): \")) * 365\n",
    "t_first_age = 22 * 365\n",
    "\n",
    "if data_loc == 2: # testing internal benchmark\n",
    "    t_first = np.load(\"regression_data/test/internal.npy\").flatten()\n",
    "    t_first_age = 4380\n",
    "\n",
    "for i in range (t_first_age, t_first_age * 2, 10):\n",
    "    t_start_photos.append(t_first)\n",
    "    t_start_ages.append(t_first_age)\n",
    "    t_target_ages.append(i)\n",
    "\n",
    "t_X = []\n",
    "for i in range(len(t_start_photos)):\n",
    "    t_X.append(np.concatenate([t_start_photos[i], t_start_ages[i], t_target_ages[i]], axis=None))\n",
    "\n",
    "methods = [\"first\", \"linear_first\", \"norm_linear_first\"]    \n",
    "results_paths = []\n",
    "\n",
    "for method in methods:\n",
    "    \n",
    "    results_path = \"regression_data/results/dimensions/\" + method + \"_\" + str(dimensions) + data_method\n",
    "    results_paths.append(results_path)\n",
    "    \n",
    "    t_Y_differences = regressor_first_10.predict(t_X)\n",
    "    if method == \"linear_first\":\n",
    "        t_Y_differences = regressor_smallest_variance.predict(t_X)\n",
    "    if method == \"norm_linear_first\":\n",
    "        t_Y_differences = regressor_normalized_smallest_variance.predict(t_X)\n",
    "    \n",
    "    t_Y = []\n",
    "\n",
    "    for i, difference in enumerate(t_Y_differences):\n",
    "        t_Y.append(t_start_photos[i] + difference)\n",
    "\n",
    "    if not os.path.exists(results_path):\n",
    "        os.mkdir(results_path)\n",
    "\n",
    "    frames = 60\n",
    "\n",
    "    for i, prediction in enumerate(t_Y):\n",
    "        img = generate_image(prediction, 512)\n",
    "        img.save(results_path + \"/\" + str(i) + \".png\")\n",
    "        frames = i\n",
    "\n",
    "    print(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "framerate = math.ceil(frames / 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffmpeg -f image2 -framerate 119 -pattern_type sequence -start_number 0 -r 2 -i %d.png -vcodec libx264 -acodec aac real_broken.mp4\n",
    "# ffmpeg -i real_broken.mp4 -c:v libx264 -profile:v baseline -level 3.0 -pix_fmt yuv420p real.mp4\n",
    "# ffmpeg -itsscale 0.027 -i real.mp4 -c copy real_output.mp4\n",
    "# os.getcwd()\n",
    "# First, manually check current path and if it is a father folder, execute chdir \n",
    "\n",
    "for results_path in results_paths:\n",
    "\n",
    "    os.chdir(\"/home/shavit/APhotoADay/True_vs_Learned/\" + results_path)\n",
    "\n",
    "    res1 = os.system(\"ffmpeg -f image2 -framerate \" + str(framerate) + \" -pattern_type sequence -start_number 0 -r 2 -i %d.png -vcodec libx264 -acodec aac real_broken.mp4\")\n",
    "    \n",
    "    if res1 == 0:\n",
    "        res2 =os.system(\"ffmpeg -i real_broken.mp4 -c:v libx264 -profile:v baseline -level 3.0 -pix_fmt yuv420p real.mp4\")\n",
    "        \n",
    "        if res2 == 0:\n",
    "            res3 = os.system(\"ffmpeg -itsscale 0.027 -i real.mp4 -c copy output.mp4\")\n",
    "            \n",
    "            if res3 == 0:\n",
    "                os.system(\"rm real_broken.mp4\")\n",
    "                os.system(\"rm real.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
