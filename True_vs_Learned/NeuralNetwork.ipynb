{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/jacobsela/a-photo-a-day/ea2f4a45ddc34d43b69de4b651413e9f\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss [161]               : (0.018330425024032593, 0.050208356231451035)\n",
      "COMET INFO:     batch_mean_squared_error [161] : (0.019251085817813873, 0.050208356231451035)\n",
      "COMET INFO:     epoch_duration [9]             : (0.18015733300035208, 5.83610296400002)\n",
      "COMET INFO:     loss [9]                       : (0.018540554866194724, 0.02277167149254533)\n",
      "COMET INFO:     mean_squared_error [9]         : (0.022263336926698685, 0.023175694048404694)\n",
      "COMET INFO:   Others [count]:\n",
      "COMET INFO:     trainable_params [3] : 2774316\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad       : 1\n",
      "COMET INFO:     Adam_beta_1        : 0.9\n",
      "COMET INFO:     Adam_beta_2        : 0.999\n",
      "COMET INFO:     Adam_decay         : 1\n",
      "COMET INFO:     Adam_epsilon       : 1e-07\n",
      "COMET INFO:     Adam_learning_rate : 0.001\n",
      "COMET INFO:     Adam_name          : Adam\n",
      "COMET INFO:     Optimizer          : Adam\n",
      "COMET INFO:     batch_size         : 32\n",
      "COMET INFO:     epochs             : 3\n",
      "COMET INFO:     samples            : 6100\n",
      "COMET INFO:     steps              : 191\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/jacobsela/a-photo-a-day/61dfff6101f64ee8b5038007a6eccab3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "experiment = comet_ml.Experiment(api_key = \"1OR6MquthzWmNUZ37ADRp4uWG\", project_name = \"a-photo-a-day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "# data is a list of lists where the first element is the age and the second is the latent representation\n",
    "\n",
    "# i.e. data[0] contains the entire first video\n",
    "# data[0][0] is a list of two values (the first age of the video, and the latent representation of the photo at that age)\n",
    "\n",
    "data = []\n",
    "\n",
    "video = []\n",
    "\n",
    "paths = [\"video1_latent_representations\",\n",
    "         \"video2_latent_representations\",\n",
    "         \"video3_latent_representations\"]\n",
    "\n",
    "for path in paths:\n",
    "    \n",
    "    for photo in os.listdir(path):\n",
    "\n",
    "        latent_representation = np.load(path + \"/\" + photo).flatten()\n",
    "        age = int(Path(photo).stem)\n",
    "\n",
    "        video.append([age, latent_representation])\n",
    "        video.sort()\n",
    "        \n",
    "    data.append(video)\n",
    "    video = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = []\n",
    "\n",
    "for person in data:\n",
    "    for j, photo in enumerate(person):\n",
    "        if j == 0:\n",
    "            continue\n",
    "        differences.append(photo[1] - person[j - 1][1])\n",
    "\n",
    "differences = np.array(differences)\n",
    "\n",
    "differences_aux = differences.transpose()\n",
    "\n",
    "variances = []\n",
    "\n",
    "for values in differences_aux:\n",
    "    variances.append(np.var(values))\n",
    "    \n",
    "# list of components sorted by variance\n",
    "smallest_variance_components = np.argsort(variances)\n",
    "\n",
    "np.save(\"svc\", smallest_variance_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Input(512*18 + 2),\n",
    "    keras.layers.Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.l1(0.0000)),\n",
    "    keras.layers.Dense(512*18)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=['mean_squared_error'],\n",
    "              metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.concatenate((np.array([data[2][0][0],data[2][len(data[2]) - 1][0]]), data[2][0][1]))\n",
    "#Y = data[2][len(data[2]) - 1][1]\n",
    "#print(X.shape)\n",
    "#print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "total_num_photos = iterations * (len(data[0]) + len(data[1]) + len(data[2]))\n",
    "X = np.empty(shape=(total_num_photos, 512*18+2))\n",
    "Y = np.empty(shape=(total_num_photos, 512*18))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    for person in data:\n",
    "        for j, photo in enumerate(person):\n",
    "            while (abs(y_aux - j) < 10):\n",
    "                y_aux = random.randint(0, len(person) - 1)\n",
    "            Y[i] = person[y_aux][1]\n",
    "            X[i] = np.concatenate((np.array([photo[0],person[y_aux][0]]), photo[1]))\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6100 samples\n",
      "Epoch 1/3\n",
      "6100/6100 [==============================] - 4s 648us/sample - loss: 0.0224 - mean_squared_error: 0.0224\n",
      "Epoch 2/3\n",
      "6100/6100 [==============================] - 3s 573us/sample - loss: 0.0221 - mean_squared_error: 0.0221\n",
      "Epoch 3/3\n",
      "6100/6100 [==============================] - 3s 564us/sample - loss: 0.0223 - mean_squared_error: 0.0223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x156ec17b8>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X), np.array(Y), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"100_hidden_forced_distance_most_linear.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
